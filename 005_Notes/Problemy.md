# Dotychczasowo rozwiązane problemy

# 1. Załadowanie wytrenowanego modelu do przeglądarki i uruchomienie go po sronie klienta 

Jednym z problemó przy pracy z danymi medycznymi jest to, że nie mogą one opuścić sieci wewętrznej szpitala. Dlatego nie możemy uruchomić wytrenowanego modelu na serwerze i zapewnić możliwości odpytania poprzez API. Rozwiązaniem w tej sytuacji było przeniessienie wytrenowanych w `tensorflow` modeli do `tensorflowjs` który pozwala na użycie ich na komputerze klienckim. Pierwszym krokiem było przekształcenie modelu z biblioteki pythonowej na bibliotekę javascriptową. Można to było łatwo wykonać w skrypcie pythonowym za pomocą metody `tfjs.converters.save_keras_model`, której przekazujemy model oraz ścieżkę do niego. Największym problemem w tej zmianie było jednak to, że aby użyć biblioteki w javascript opercaje przez nią wykonywane musiały być poza wątkiem głównym, w celu nie blokowania UI - jest to narzucane przez samą bilbiotekę.

Aby to osiągnąć posłużyłem się takzwanymi webworker-ami. Pozwalają one na wykonywanie zadań równolegle do wątku głównego.  W wątku głównym tworzymy obiekt  klasy `Worker` oraz subskybujemy wydarzenie `worker.onmessage`. Dzięki temu możemy wykonać opercję na danych otrzymanych w wiadomości. Natomiast w celu wysłania zapytania do workera używamy metody `worker.postMessgae` w której przekazujemy dane. W moim wypadku była to pobrana z wyświetlonej kanwy tablica z danymi o pikselach w obrazku. W skrypcie zawierjącym kod źródłowy workera również subskrybujemy wydarzenie `onmessage`, w jego obsludze najpierw preprocesuję dane w ten sposób aby ich format na wejście był taki sam jak danych uczących. Jest to wymagane nawet jeżeli chcielibyśmy sprawdzić model kożystając z tego samego obrazu ponieważ biblioteki `PIL` oraz `NumPy` mają inny format danych niż dane zwrócone przy pomocy javascript z obiektu `canvas` dostępnego w HTML5 na którym wyświetlany był obraz do klasyfikacji. Następnie po doprowadzeniu otrzymanych daych do odpowiedniego formatu jesteśmy w stanie użyć wyuczonego w pythonie i tensorflow modelu w celu uzyskania predykcji. Następnie za pomocą metody `postMessage` jesteżmy w stanie wysłać do wątku głównego wiadomość zawierającą predykcję modelu, który ją wyświetli.

Dzięki powyrzszemu rozwiązaniu jesteśmy w stanie uruchmić nasz model postronie klienta w przeglądarce. Dodatkowo zapewniona jest płynność działania ponieważ procesowanie danych oraz predykcja modelu wykonywane są równolegle do wątku głównego, który obsługuje interfejs użytkownika.

# 2. Zbyt duża wielkość obrazów wejsciowych oraz mała ilość danych uczących 