{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPDRlmj0TwkBPACD3J2YfSz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtracewicz/DiplomaSeminar/blob/master/unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p0FnwJEKbQT"
      },
      "source": [
        "# U-NET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgDHYVjDKPMD"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b80WdhSKMOm"
      },
      "source": [
        "import sys\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64iV_BgeKRWe"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryjgo3fDKNab"
      },
      "source": [
        "learning_rate = 0.01\n",
        "epochs = 40\n",
        "batch_size = 4000\n",
        "validation_split = 0.2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZyaFszcMNjB"
      },
      "source": [
        "## Args"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UoChkzYMPgE"
      },
      "source": [
        "checkpoint_name = \"unet\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Laf-5RKr-5"
      },
      "source": [
        "## Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biT90WvKKuem"
      },
      "source": [
        "def create_model(learning_rate):\n",
        "    # Model creation\n",
        "    model = tf.keras.models.Sequential()\n",
        "    # Downsampling\n",
        "    model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2,\n",
        "                                     padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2,\n",
        "                                     padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2,\n",
        "                                     padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "\n",
        "    #Flat\n",
        "    model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2,\n",
        "                                     padding='same', activation='relu'))\n",
        "    # Upsampling\n",
        "    model.add(tf.keras.layers.UpSampling2D())\n",
        "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2,\n",
        "                                     padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "    model.add(tf.keras.layers.UpSampling2D())\n",
        "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2,\n",
        "                                     padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.UpSampling2D())\n",
        "    model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2,\n",
        "                                     padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "\n",
        "    #Flatenning\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(units=512, activation='sigmoid'))\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBveTiw0KwGo"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMmRLdARJbXf"
      },
      "source": [
        "def save_model(model):\n",
        "    # Saving compiled model\n",
        "    tf.keras.models.save_model(\n",
        "        model, f'./checkpoints/{checkpoint_name}/{checkpoint_name}')\n",
        "\n",
        "    # and its topograpy\n",
        "    with open(f'./checkpoints/{checkpoint_name}/{checkpoint_name}.json', \"w\") as file:\n",
        "        file.write(model.to_json())\n",
        "        file.flush()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkDvHVVPLAol"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhtrnXfhLD_D",
        "outputId": "c4fd2f4f-3f3e-49ca-e25b-62eec7de3b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "    # Loading data\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    # Data normalization from [0,255] to [0.0,1.0]\n",
        "    # and reshaping it for proper dimensions\n",
        "    x_train_normalized = (x_train/255.0).reshape(x_train.shape[0], 28, 28, 1)\n",
        "    x_test_normalized = (x_test/255.0).reshape(x_test.shape[0], 28, 28, 1)\n",
        "    # Establish the model's topography.\n",
        "    model = create_model(learning_rate)\n",
        "    # Train the model on the normalized training set.\n",
        "    model.fit(x=x_train_normalized, y=y_train, batch_size=batch_size,\n",
        "              epochs=epochs, shuffle=True,\n",
        "              validation_split=validation_split)\n",
        "    # Evaluate against the test set.\n",
        "    print(\"\\n Evaluate the new model against the test set:\")\n",
        "    model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)\n",
        "    save_model(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/40\n",
            " 2/12 [====>.........................] - ETA: 0s - loss: 3.6941 - accuracy: 0.0978WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0203s vs `on_train_batch_end` time: 0.1033s). Check your callbacks.\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.6056 - accuracy: 0.1016WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0048s vs `on_test_batch_end` time: 0.0328s). Check your callbacks.\n",
            "12/12 [==============================] - 2s 148ms/step - loss: 3.6056 - accuracy: 0.1016 - val_loss: 2.8664 - val_accuracy: 0.0914\n",
            "Epoch 2/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.6683 - accuracy: 0.0998 - val_loss: 2.4847 - val_accuracy: 0.1035\n",
            "Epoch 3/40\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 2.4514 - accuracy: 0.0998 - val_loss: 2.3275 - val_accuracy: 0.1035\n",
            "Epoch 4/40\n",
            "12/12 [==============================] - 2s 131ms/step - loss: 2.3956 - accuracy: 0.1005 - val_loss: 2.3064 - val_accuracy: 0.1060\n",
            "Epoch 5/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3693 - accuracy: 0.1006 - val_loss: 2.3071 - val_accuracy: 0.0989\n",
            "Epoch 6/40\n",
            "12/12 [==============================] - 2s 131ms/step - loss: 2.3593 - accuracy: 0.1011 - val_loss: 2.3124 - val_accuracy: 0.0989\n",
            "Epoch 7/40\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 2.3514 - accuracy: 0.1035 - val_loss: 2.3038 - val_accuracy: 0.1081\n",
            "Epoch 8/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3408 - accuracy: 0.1026 - val_loss: 2.3035 - val_accuracy: 0.1060\n",
            "Epoch 9/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3348 - accuracy: 0.1016 - val_loss: 2.3060 - val_accuracy: 0.1060\n",
            "Epoch 10/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3308 - accuracy: 0.1014 - val_loss: 2.3073 - val_accuracy: 0.1060\n",
            "Epoch 11/40\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 2.3258 - accuracy: 0.1040 - val_loss: 2.3046 - val_accuracy: 0.0997\n",
            "Epoch 12/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3241 - accuracy: 0.1003 - val_loss: 2.3083 - val_accuracy: 0.1060\n",
            "Epoch 13/40\n",
            "12/12 [==============================] - 2s 131ms/step - loss: 2.3246 - accuracy: 0.1038 - val_loss: 2.3120 - val_accuracy: 0.0998\n",
            "Epoch 14/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3210 - accuracy: 0.1018 - val_loss: 2.3058 - val_accuracy: 0.1060\n",
            "Epoch 15/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3166 - accuracy: 0.1054 - val_loss: 2.3041 - val_accuracy: 0.1060\n",
            "Epoch 16/40\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 2.3208 - accuracy: 0.1031 - val_loss: 2.3112 - val_accuracy: 0.1060\n",
            "Epoch 17/40\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 2.3143 - accuracy: 0.1046 - val_loss: 2.3053 - val_accuracy: 0.0975\n",
            "Epoch 18/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3122 - accuracy: 0.1036 - val_loss: 2.3197 - val_accuracy: 0.1060\n",
            "Epoch 19/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3226 - accuracy: 0.1014 - val_loss: 2.3195 - val_accuracy: 0.0989\n",
            "Epoch 20/40\n",
            "12/12 [==============================] - 2s 131ms/step - loss: 2.3158 - accuracy: 0.1029 - val_loss: 2.3095 - val_accuracy: 0.0989\n",
            "Epoch 21/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3113 - accuracy: 0.1045 - val_loss: 2.3058 - val_accuracy: 0.1060\n",
            "Epoch 22/40\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 2.3089 - accuracy: 0.1037 - val_loss: 2.3114 - val_accuracy: 0.1060\n",
            "Epoch 23/40\n",
            "12/12 [==============================] - 2s 134ms/step - loss: 2.3106 - accuracy: 0.1046 - val_loss: 2.3121 - val_accuracy: 0.1060\n",
            "Epoch 24/40\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 2.3151 - accuracy: 0.1030 - val_loss: 2.3098 - val_accuracy: 0.0998\n",
            "Epoch 25/40\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 2.3142 - accuracy: 0.1046 - val_loss: 2.3124 - val_accuracy: 0.0997\n",
            "Epoch 26/40\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 2.3157 - accuracy: 0.1036 - val_loss: 2.3207 - val_accuracy: 0.1060\n",
            "Epoch 27/40\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 2.3153 - accuracy: 0.1066 - val_loss: 2.3105 - val_accuracy: 0.1060\n",
            "Epoch 28/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3094 - accuracy: 0.1035 - val_loss: 2.3047 - val_accuracy: 0.0989\n",
            "Epoch 29/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3096 - accuracy: 0.1020 - val_loss: 2.3101 - val_accuracy: 0.1060\n",
            "Epoch 30/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3140 - accuracy: 0.1029 - val_loss: 2.3122 - val_accuracy: 0.0997\n",
            "Epoch 31/40\n",
            "12/12 [==============================] - 2s 131ms/step - loss: 2.3171 - accuracy: 0.1024 - val_loss: 2.3116 - val_accuracy: 0.0997\n",
            "Epoch 32/40\n",
            "12/12 [==============================] - 2s 131ms/step - loss: 2.3141 - accuracy: 0.1014 - val_loss: 2.3062 - val_accuracy: 0.0998\n",
            "Epoch 33/40\n",
            "12/12 [==============================] - 2s 131ms/step - loss: 2.3132 - accuracy: 0.1051 - val_loss: 2.3151 - val_accuracy: 0.0998\n",
            "Epoch 34/40\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 2.3125 - accuracy: 0.1018 - val_loss: 2.3132 - val_accuracy: 0.0997\n",
            "Epoch 35/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3086 - accuracy: 0.1011 - val_loss: 2.3125 - val_accuracy: 0.1060\n",
            "Epoch 36/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3104 - accuracy: 0.1045 - val_loss: 2.3087 - val_accuracy: 0.1081\n",
            "Epoch 37/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3155 - accuracy: 0.1005 - val_loss: 2.3166 - val_accuracy: 0.1060\n",
            "Epoch 38/40\n",
            "12/12 [==============================] - 2s 134ms/step - loss: 2.3130 - accuracy: 0.1011 - val_loss: 2.3145 - val_accuracy: 0.1060\n",
            "Epoch 39/40\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.3156 - accuracy: 0.1050 - val_loss: 2.3103 - val_accuracy: 0.0975\n",
            "Epoch 40/40\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 2.3141 - accuracy: 0.0993 - val_loss: 2.3084 - val_accuracy: 0.0914\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 2.3092 - accuracy: 0.0892\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: ./checkpoints/unet/unet/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}